(1)引擎       ---》自动运行，无需关注，会自动组织所有的请求对象，分发给下载器
(2)下载器      ---》从引擎处获取到请求对象后，请求数据---》spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。
(3)spiders
(4)调度器      ---》有自己的调度规则，无需关注
(5)管道(ytem pipeline)        ---》最终处理数据的管道，会预留接口供我们处理数据当Item在spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。
以下是item pipeline的一些典型应用:
1.清理HTML数据
2，验证爬取的数据(检查item包含某些字段)
3.查重(井丢弃)
4.将爬取结果保存到数据库中